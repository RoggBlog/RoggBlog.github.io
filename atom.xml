<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Rogg 罗格</title>
  
  <subtitle>Stay Hungry, Stay Foolish</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://stark365.com/"/>
  <updated>2019-04-15T01:59:19.431Z</updated>
  <id>http://stark365.com/</id>
  
  <author>
    <name>Rogg 罗格</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>卷积神经网络</title>
    <link href="http://stark365.com/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://stark365.com/卷积神经网络/</id>
    <published>2019-04-14T06:11:04.864Z</published>
    <updated>2019-04-15T01:59:19.431Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p>卷积神经网络的特点是把<strong>隐层</strong>分为<strong>卷积层</strong>和<strong>池化层</strong></p><ul><li>卷积层：通过在原始图像上平移来提取特征</li><li>池化层：通过特征后稀疏参数来减少学习的参数，降低网络的复杂度（最大池化和平均池化）</li></ul><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><ul><li>卷积层过滤器</li><li>激活函数</li><li>池化层</li><li>全连接层</li></ul><h2 id="filter体积公式"><a href="#filter体积公式" class="headerlink" title="filter体积公式"></a>filter体积公式</h2><p>输入体积大小：\(H_1 <em> W_1 </em> D_1\)</p><ul><li>Filter 超参数<ul><li>Filter 数量 \(K\)</li><li>Filter 大小 \(F\)</li><li>步长 \(S\)</li><li>零填充大小 \(P\)</li></ul></li></ul><p>输出体积大小：\(H_2 <em> W_2 </em> D_2\)</p><p>$$ H_2 = \frac{H_1-F+2P}{S}+1 $$</p><p>$$ W_2 = \frac{W_1-F+2P}{S}+1 $$</p><p>$$ D_2 = K $$</p><h2 id="卷积网络-API"><a href="#卷积网络-API" class="headerlink" title="卷积网络 API"></a>卷积网络 API</h2><p>计算给定 4-D input 和 filter 张量的二维卷积</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.conv2d(input, filter, strides, padding, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><ul><li>input：给定的输入张量，具有[batch, height, width, channel]，类型为float32/64</li><li>filter：指定过滤器的大小，[filter_height，filter_width,in_channels(原图片通道), out_channels(过滤器数量)]</li><li>strides：strides = [1, stride, stride, 1], 步长</li><li>padding：”SAME”、”VALID”，使用的填充算法类型。”VALID”表示 filter 移动后超出图片部分舍弃；”SAME”表示填充</li></ul><h2 id="激活函数-API"><a href="#激活函数-API" class="headerlink" title="激活函数 API"></a>激活函数 API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.relu(features, name=<span class="literal">None</span>)  <span class="comment"># 返回结果</span></span><br></pre></td></tr></table></figure><ul><li>features:卷积后加上偏置的结果</li></ul><h2 id="池化层计算"><a href="#池化层计算" class="headerlink" title="池化层计算"></a>池化层计算</h2><p>Pooling 层主要的作用是特征提取，通过去掉 Feature Map 中不重要的样本，进一步减少参数数量。Pooling 的方法很多，最常用的是 Max Pooling 2*2 2步长</p><h3 id="池化-API"><a href="#池化-API" class="headerlink" title="池化 API"></a>池化 API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.max_pool(value, ksize=, strides=, padding=, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><ul><li>value：4-D Tensor 形状，[batch, height, width, channels]</li><li>ksize：池化窗口大小，[1, ksize, ksize, 1]</li><li>strides：步长大小, [1, strides, strides, 1]</li><li>padding：”SAME”、”VALID”，使用的填充算法类型。”VALID”表示 filter 移动后超出图片部分舍弃；”SAME”表示填充</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;卷积神经网络&quot;&gt;&lt;a href=&quot;#卷积
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>神经网络</title>
    <link href="http://stark365.com/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://stark365.com/神经网络/</id>
    <published>2019-04-12T06:38:22.530Z</published>
    <updated>2019-04-15T01:41:55.281Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><h3 id="基础神经网络"><a href="#基础神经网络" class="headerlink" title="基础神经网络"></a>基础神经网络</h3><p>单层感知器等</p><h3 id="进阶神经网络"><a href="#进阶神经网络" class="headerlink" title="进阶神经网络"></a>进阶神经网络</h3><p>玻尔兹曼机等</p><h3 id="深度神经网络"><a href="#深度神经网络" class="headerlink" title="深度神经网络"></a>深度神经网络</h3><p>深度置信网络，卷积神经网络，循环神经网络，LSTM 网络</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul><li>输入向量的维度和输入神经元的个数相同</li><li>每个链接都有权值, 权值数=特征数*神经元个数,偏置=神经元个数</li><li>同一层神经元之间没有连接</li><li>由输入层、隐层、输出层组成</li><li>第 N 层与第 N-1 层的所有神经元连接，称全连接</li></ul><h2 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h2><ul><li>结构：权重、神经元等</li><li>激活函数</li><li>学习规则：学习规则制定了网络中的权重如何随着时间推进而调整(<strong>反向传播算法</strong>)</li></ul><h2 id="SoftMax-回归"><a href="#SoftMax-回归" class="headerlink" title="SoftMax 回归"></a>SoftMax 回归</h2><h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>$$ S_i=\frac{e^i}{\sum_j e^j } $$</p><ul><li>e = 2.71</li><li>i 为全连接层 SoftMax 需要计算的神经元输出</li></ul><p>$$ \sum_j e^j = \frac{e^1}{e^1+e^2+e^3+···} $$</p><h3 id="SoftMax计算、交叉熵-API"><a href="#SoftMax计算、交叉熵-API" class="headerlink" title="SoftMax计算、交叉熵 API"></a>SoftMax计算、交叉熵 API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.softmax_cross_entropy_with_logits(labels=<span class="literal">None</span>, logits=<span class="literal">None</span>, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>计算预测值与真实值之间的交叉损失熵</p><ul><li>labels 真实值</li><li>logits 预测值</li></ul><p>返回损失值列表</p><h3 id="准确性计算"><a href="#准确性计算" class="headerlink" title="准确性计算"></a>准确性计算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">equal_list = tf.equal(tf.argmax(y_true, <span class="number">1</span>), tf.argmax(y_predict, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(equal_list, tf.float32))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;神经网络&quot;&gt;&lt;a href=&quot;#神经网络
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>TFRecords</title>
    <link href="http://stark365.com/TFRecords/"/>
    <id>http://stark365.com/TFRecords/</id>
    <published>2019-04-11T07:33:27.971Z</published>
    <updated>2019-04-14T01:06:05.029Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TFRecords"><a href="#TFRecords" class="headerlink" title="TFRecords"></a>TFRecords</h1><h2 id="建立-TFRecords-储存器"><a href="#建立-TFRecords-储存器" class="headerlink" title="建立 TFRecords 储存器"></a>建立 TFRecords 储存器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.python_io.TFRecordWriter(path)  <span class="comment"># 返回写文件</span></span><br></pre></td></tr></table></figure><p>参数</p><ul><li>path 文件的路径</li></ul><p>方法</p><ul><li>write(record)  向文件中写入一个 Example</li><li>close()  关闭写入器</li></ul><blockquote><p>Example(类字典) = Example.SerializeToString()</p></blockquote><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><h3 id="写入-tfrecords-文件"><a href="#写入-tfrecords-文件" class="headerlink" title="写入 tfrecords 文件"></a>写入 tfrecords 文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.Example(features=<span class="literal">None</span>)  <span class="comment"># 返回 Example 格式协议块</span></span><br></pre></td></tr></table></figure><ul><li>features Features类型的特征实例对象</li></ul><h3 id="构建每个样本的信息键值对"><a href="#构建每个样本的信息键值对" class="headerlink" title="构建每个样本的信息键值对"></a>构建每个样本的信息键值对</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.Features(feature=<span class="literal">None</span>)  <span class="comment"># 返回 Features 类型数据</span></span><br></pre></td></tr></table></figure><ul><li>feature 字典类型数据，key 为要保存的名字，value 为 tf.train.Feature 实例对象</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.Feature(**options)  <span class="comment"># 返回 Feature 实例对象</span></span><br></pre></td></tr></table></figure><ul><li>**options：<ul><li>bytes_list = tf.train.BytesList(value=[Bytes])</li><li>int64_list = tf.train.Int64List(value=[Value])</li><li>float_list = tf.train.FloatList(value=[Value])</li></ul></li></ul><h2 id="TFRecords-文件的读取"><a href="#TFRecords-文件的读取" class="headerlink" title="TFRecords 文件的读取"></a>TFRecords 文件的读取</h2><p>与读取普通文件流程几乎一致，但中间需要添加解析</p><h3 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h3><p>解析 TFRecords 的 example 协议内存块</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.parse_single_example(serialize, features=<span class="literal">None</span>, name=<span class="literal">None</span>)  <span class="comment"># 返回一个字典，键为读取的名字，值为内容</span></span><br></pre></td></tr></table></figure><ul><li>serialized 标量字符串 Tensor，一个序列化的 Example</li><li>features 字典数据，键为读取的名字，值为 FixedLenFeature</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.FixedLenFeature(shape, dtype)</span><br></pre></td></tr></table></figure><ul><li>shape 输入数据的形状，一般不指定，为空列表</li><li>dtype 输入数据类型，与储存进文件的类型要一致</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TFRecords&quot;&gt;&lt;a href=&quot;#TFRecords&quot; class=&quot;headerlink&quot; title=&quot;TFRecords&quot;&gt;&lt;/a&gt;TFRecords&lt;/h1&gt;&lt;h2 id=&quot;建立-TFRecords-储存器&quot;&gt;&lt;a href=&quot;#建立-TFReco
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>图像读取</title>
    <link href="http://stark365.com/%E5%9B%BE%E5%83%8F%E8%AF%BB%E5%8F%96/"/>
    <id>http://stark365.com/图像读取/</id>
    <published>2019-04-11T01:44:29.899Z</published>
    <updated>2019-04-14T01:06:01.623Z</updated>
    
    <content type="html"><![CDATA[<h1 id="图像读取"><a href="#图像读取" class="headerlink" title="图像读取"></a>图像读取</h1><p>做图片处理时，需要所有图片特征数量统一(像素一致)</p><p>目的：</p><ol><li>增加图片数据的统一性</li><li>所有图片转换成指定大小</li><li>缩小图片数据量，防止增加开销</li></ol><h2 id="缩放图片"><a href="#缩放图片" class="headerlink" title="缩放图片"></a>缩放图片</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image_resize = tf.image.resize_images(images, size)  <span class="comment"># 返回 4-D 格式或者 3-D 格式图片</span></span><br></pre></td></tr></table></figure><p>图片缩放后会从 uint8 变为 float32 类型</p><ul><li>images 4-D 形状 [batch, height, width, channels] 或 3-D 形状的张量 [height, width, channels] 的图片数据</li><li>size 1-D int32 张量 [new_height, new_width] 图像的新尺寸</li></ul><blockquote><p>注意，在批处理的时候要求所有数据必须定义图片需要指定通道：image_resize.set_shape([200, 200, 3])</p></blockquote><h2 id="图片读取器"><a href="#图片读取器" class="headerlink" title="图片读取器"></a>图片读取器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.WholeFileReader  <span class="comment"># 返回读取器实例对象</span></span><br></pre></td></tr></table></figure><p>read(file_queue) 输出文件名(key)和该文件的内容(value)</p><h2 id="图像解码器"><a href="#图像解码器" class="headerlink" title="图像解码器"></a>图像解码器</h2><h3 id="jpeg"><a href="#jpeg" class="headerlink" title="jpeg"></a>jpeg</h3><p>将 JPEG 图像解码为 uint8 张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image = tf.image.decode_jpeg(contents)  <span class="comment"># 返回 uint8 张量， 3-D 形状</span></span><br></pre></td></tr></table></figure><ul><li>contents 就是读取器读取的文件内容(value)</li></ul><h3 id="png"><a href="#png" class="headerlink" title="png"></a>png</h3><p>将 PNG 图像解码为 uint8 或 uint16 张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image = tf.image.decode_png(contents)  <span class="comment"># 返回张量， 3-D 形状</span></span><br></pre></td></tr></table></figure><ul><li>contents 就是读取器读取的文件内容(value)</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;图像读取&quot;&gt;&lt;a href=&quot;#图像读取&quot; class=&quot;headerlink&quot; title=&quot;图像读取&quot;&gt;&lt;/a&gt;图像读取&lt;/h1&gt;&lt;p&gt;做图片处理时，需要所有图片特征数量统一(像素一致)&lt;/p&gt;
&lt;p&gt;目的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;增加图片数据的统一性&lt;/
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>文件读取</title>
    <link href="http://stark365.com/%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96/"/>
    <id>http://stark365.com/文件读取/</id>
    <published>2019-04-10T06:51:37.763Z</published>
    <updated>2019-04-14T01:05:56.004Z</updated>
    
    <content type="html"><![CDATA[<h1 id="文件读取"><a href="#文件读取" class="headerlink" title="文件读取"></a>文件读取</h1><h2 id="文件队列构造"><a href="#文件队列构造" class="headerlink" title="文件队列构造"></a>文件队列构造</h2><p>将输出字符串输入到管道队列</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.string_input_producer(string_tensor, shuffle=<span class="literal">True</span>)  <span class="comment"># 返回一个队列对象</span></span><br></pre></td></tr></table></figure><ul><li>string_tensor 含有文件名的1阶张量(列表)</li><li>shuffle 是否乱序</li></ul><h2 id="文件阅读器"><a href="#文件阅读器" class="headerlink" title="文件阅读器"></a>文件阅读器</h2><h3 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.TextLineReader()  <span class="comment"># 返回阅读器实例</span></span><br></pre></td></tr></table></figure><h3 id="二进制"><a href="#二进制" class="headerlink" title="二进制"></a>二进制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.FixedLengthRecordReader(record_bytes)  <span class="comment"># 返回阅读器实例</span></span><br></pre></td></tr></table></figure><ul><li>record_bytes 整型，指每次读取的字节数</li></ul><h3 id="TFRecords"><a href="#TFRecords" class="headerlink" title="TFRecords"></a>TFRecords</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.TFRecordReader()</span><br></pre></td></tr></table></figure><blockquote><p>都有一个公共方法 read(),返回 keys values</p></blockquote><h2 id="文件内容解码器"><a href="#文件内容解码器" class="headerlink" title="文件内容解码器"></a>文件内容解码器</h2><p>从文件当中读取的是字符串，需要函数去解析这些字符串到张量</p><h3 id="CSV-1"><a href="#CSV-1" class="headerlink" title="CSV"></a>CSV</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.decode_csv(records, record_defaults=<span class="literal">None</span>, field_delim=<span class="literal">None</span>, name=<span class="literal">None</span>)  <span class="comment"># 有多少个列，则返回多个个列</span></span><br></pre></td></tr></table></figure><ul><li>records 张量型字符串，每个字符串是 csv 中的记录行</li><li>field_delim 分隔符，默认“,”</li><li>record_defaults 参数决定了所得张量的类型，并设置一个值在输入字符串中缺少使用默认值</li></ul><h3 id="二进制-1"><a href="#二进制-1" class="headerlink" title="二进制"></a>二进制</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.decode_raw(bytes, out_type, little_endian=<span class="literal">None</span>, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;文件读取&quot;&gt;&lt;a href=&quot;#文件读取&quot; class=&quot;headerlink&quot; title=&quot;文件读取&quot;&gt;&lt;/a&gt;文件读取&lt;/h1&gt;&lt;h2 id=&quot;文件队列构造&quot;&gt;&lt;a href=&quot;#文件队列构造&quot; class=&quot;headerlink&quot; title=&quot;文件队列构
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>线程队列与IO操作</title>
    <link href="http://stark365.com/%E7%BA%BF%E7%A8%8B%E9%98%9F%E5%88%97%E4%B8%8EIO%E6%93%8D%E4%BD%9C/"/>
    <id>http://stark365.com/线程队列与IO操作/</id>
    <published>2019-04-09T02:41:09.974Z</published>
    <updated>2019-04-11T00:47:05.424Z</updated>
    
    <content type="html"><![CDATA[<h1 id="线程队列"><a href="#线程队列" class="headerlink" title="线程队列"></a>线程队列</h1><h2 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先进先出队列</span></span><br><span class="line">tf.FIFOQueue(capacity, dtypes, name=<span class="string">""</span>)</span><br></pre></td></tr></table></figure><ul><li>capacity 整数，可存储的元素数量上限</li><li>dtypes 列表，dtypes长度必须等于每个队列元素中的张量数，dtypes的类型形状决定了后面进队列元素的形状</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 随机出队列</span></span><br><span class="line">tf.RandomShuffleQueue</span><br></pre></td></tr></table></figure><h2 id="队列管理器"><a href="#队列管理器" class="headerlink" title="队列管理器"></a>队列管理器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.QueueRunner(queue, enqueue_ops=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><ul><li>queue 队列</li><li>enqueue_ops  添加线程的队列操作列表，[]*2 指定两个线程</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建线程来运行给定会话的入队操作</span></span><br><span class="line">create_threads(sess, coord=<span class="literal">None</span>, start=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li>coord 线程协调器，后面线程管理需要用到</li><li>start True启动线程，False必须手动调用 start() 启动线程。</li><li>return 线程的实例</li></ul><h2 id="线程协调器"><a href="#线程协调器" class="headerlink" title="线程协调器"></a>线程协调器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.Coordinator()</span><br></pre></td></tr></table></figure><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ul><li>request_stop()  # 请求停止</li><li>should_stop()  # 强制停止</li><li>join(threads=None, stop_grace_period_secs=120)    # 等待线程终止</li></ul><p>return 线程协调员实例</p><h2 id="开启线程操作"><a href="#开启线程操作" class="headerlink" title="开启线程操作"></a>开启线程操作</h2><p>收集所有图中的队列线程，并开启线程</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.start_queue_runners(sess=<span class="literal">None</span>, coord=<span class="literal">None</span>)  <span class="comment"># 返回所有线程队列</span></span><br></pre></td></tr></table></figure><ul><li>sess 会话</li><li>coord 线程协调器</li></ul><h2 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.batch(tensors, batch_size, num_threads=<span class="number">1</span>, capacity=<span class="number">32</span>, name=<span class="literal">None</span>)  <span class="comment"># 返回 tensors</span></span><br></pre></td></tr></table></figure><ul><li>tensors 可以是包含张量的列表</li><li>batch_size 从队列中读取的批处理大小</li><li>num_threads 进入队列的线程数</li><li>capacity 队列中元素的最大数量</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;线程队列&quot;&gt;&lt;a href=&quot;#线程队列&quot; class=&quot;headerlink&quot; title=&quot;线程队列&quot;&gt;&lt;/a&gt;线程队列&lt;/h1&gt;&lt;h2 id=&quot;队列&quot;&gt;&lt;a href=&quot;#队列&quot; class=&quot;headerlink&quot; title=&quot;队列&quot;&gt;&lt;/a&gt;队列&lt;/h
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>模型的保存与加载</title>
    <link href="http://stark365.com/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E5%8A%A0%E8%BD%BD/"/>
    <id>http://stark365.com/模型的保存与加载/</id>
    <published>2019-04-08T09:24:20.495Z</published>
    <updated>2019-04-08T09:43:59.342Z</updated>
    
    <content type="html"><![CDATA[<h1 id="模型的保存与加载"><a href="#模型的保存与加载" class="headerlink" title="模型的保存与加载"></a>模型的保存与加载</h1><h2 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver(var_list=<span class="literal">None</span>, max_to_keep=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">saver.save(sess,<span class="string">"/tmp/test/demo"</span>)</span><br></pre></td></tr></table></figure><ul><li>var_list 指定要保存和还原的变量，他可以作为一个字典或列表传递</li><li>max_to_keep 指示要保留的最近检查点文件的最大数量。创建新文件时，会删除较久的文件。0表示保留所有。</li></ul><h2 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">saver.restore(sess, <span class="string">"/tmp/test/demo"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;模型的保存与加载&quot;&gt;&lt;a href=&quot;#模型的保存与加载&quot; class=&quot;headerlink&quot; title=&quot;模型的保存与加载&quot;&gt;&lt;/a&gt;模型的保存与加载&lt;/h1&gt;&lt;h2 id=&quot;保存&quot;&gt;&lt;a href=&quot;#保存&quot; class=&quot;headerlink&quot; titl
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>可视化学习</title>
    <link href="http://stark365.com/%E5%8F%AF%E8%A7%86%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    <id>http://stark365.com/可视化学习/</id>
    <published>2019-04-08T08:27:47.929Z</published>
    <updated>2019-04-16T00:21:34.065Z</updated>
    
    <content type="html"><![CDATA[<h1 id="可视化学习"><a href="#可视化学习" class="headerlink" title="可视化学习"></a>可视化学习</h1><h2 id="name-属性"><a href="#name-属性" class="headerlink" title="name 属性"></a>name 属性</h2><p>在 tensorflow 后台显示，让相同 op 名字的进行区分</p><h2 id="导出事件文件"><a href="#导出事件文件" class="headerlink" title="导出事件文件"></a>导出事件文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.summary.FileWriter(<span class="string">"/路径/"</span>, graph=)</span><br></pre></td></tr></table></figure><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=<span class="string">"/路径/"</span></span><br></pre></td></tr></table></figure><p>浏览器打开 <a href="http://127.0.0.1:6006" target="_blank" rel="noopener">http://127.0.0.1:6006</a></p><h2 id="变量作用域"><a href="#变量作用域" class="headerlink" title="变量作用域"></a>变量作用域</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"name"</span>):  <span class="comment"># 创建指定名字的作用于</span></span><br></pre></td></tr></table></figure><h2 id="增加变量显示"><a href="#增加变量显示" class="headerlink" title="增加变量显示"></a>增加变量显示</h2><h3 id="收集变量"><a href="#收集变量" class="headerlink" title="收集变量"></a>收集变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tf.summary.scalar(name=<span class="string">""</span>, tensor)  <span class="comment"># 收集对于损失函数和准确率</span></span><br><span class="line"></span><br><span class="line">tf.summary.histogram(name=<span class="string">""</span>,tensor)  <span class="comment"># 收集高纬度的变量参数</span></span><br><span class="line"></span><br><span class="line">tf.summary.image(name=<span class="string">""</span>, tensor)  <span class="comment"># 收集输出的图片张量</span></span><br></pre></td></tr></table></figure><h3 id="合并变量并写入事件文件"><a href="#合并变量并写入事件文件" class="headerlink" title="合并变量并写入事件文件"></a>合并变量并写入事件文件</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">merged = tf.summary.merge_all()</span><br><span class="line">summary = sess.run(merged)  <span class="comment"># 运行合并，每次迭代都需运行</span></span><br><span class="line">filewrite.add_summary(summary, i)  <span class="comment"># 添加</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;可视化学习&quot;&gt;&lt;a href=&quot;#可视化学习&quot; class=&quot;headerlink&quot; title=&quot;可视化学习&quot;&gt;&lt;/a&gt;可视化学习&lt;/h1&gt;&lt;h2 id=&quot;name-属性&quot;&gt;&lt;a href=&quot;#name-属性&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>变量作用域</title>
    <link href="http://stark365.com/%E5%8F%98%E9%87%8F%E4%BD%9C%E7%94%A8%E5%9F%9F/"/>
    <id>http://stark365.com/变量作用域/</id>
    <published>2019-04-08T08:21:24.005Z</published>
    <updated>2019-04-08T08:22:47.126Z</updated>
    
    <content type="html"><![CDATA[<h1 id="变量作用域"><a href="#变量作用域" class="headerlink" title="变量作用域"></a>变量作用域</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(<span class="string">"name"</span>):  <span class="comment"># 创建指定名字的作用于</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;变量作用域&quot;&gt;&lt;a href=&quot;#变量作用域&quot; class=&quot;headerlink&quot; title=&quot;变量作用域&quot;&gt;&lt;/a&gt;变量作用域&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>梯度下降 API</title>
    <link href="http://stark365.com/gdo/"/>
    <id>http://stark365.com/gdo/</id>
    <published>2019-04-08T05:33:12.268Z</published>
    <updated>2019-04-14T02:05:16.759Z</updated>
    
    <content type="html"><![CDATA[<h1 id="梯度下降-API"><a href="#梯度下降-API" class="headerlink" title="梯度下降 API"></a>梯度下降 API</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.train.GradientDescentOptimizer(learning_rate)</span><br></pre></td></tr></table></figure><p>参数</p><ul><li>learning_rate 学习率</li></ul><p>方法</p><ul><li>minimize(loss) loss: 损失值</li></ul><p>返回值</p><ul><li>梯度下降 op</li></ul><h2 id="梯度爆炸-梯度消失"><a href="#梯度爆炸-梯度消失" class="headerlink" title="梯度爆炸/梯度消失"></a>梯度爆炸/梯度消失</h2><p>在极端情况下，权重的值变得非常大，以至于溢出，导致出现 NaN 值</p><p>解决方法</p><ul><li>重新设计网络</li><li>调整学习率</li><li>使用梯度截断</li><li>使用激活函数</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;梯度下降-API&quot;&gt;&lt;a href=&quot;#梯度下降-API&quot; class=&quot;headerlink&quot; title=&quot;梯度下降 API&quot;&gt;&lt;/a&gt;梯度下降 API&lt;/h1&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td c
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>运算 API</title>
    <link href="http://stark365.com/mathapi/"/>
    <id>http://stark365.com/mathapi/</id>
    <published>2019-04-08T05:28:57.995Z</published>
    <updated>2019-04-14T01:56:43.375Z</updated>
    
    <content type="html"><![CDATA[<h1 id="运算-API"><a href="#运算-API" class="headerlink" title="运算 API"></a>运算 API</h1><h2 id="矩阵相乘"><a href="#矩阵相乘" class="headerlink" title="矩阵相乘"></a>矩阵相乘</h2><p>注意：矩阵相乘必须是二维</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.matmul(x,w)</span><br></pre></td></tr></table></figure><h2 id="平方"><a href="#平方" class="headerlink" title="平方"></a>平方</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.square(X)</span><br></pre></td></tr></table></figure><h2 id="均值"><a href="#均值" class="headerlink" title="均值"></a>均值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reduce_mean(X)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;运算-API&quot;&gt;&lt;a href=&quot;#运算-API&quot; class=&quot;headerlink&quot; title=&quot;运算 API&quot;&gt;&lt;/a&gt;运算 API&lt;/h1&gt;&lt;h2 id=&quot;矩阵相乘&quot;&gt;&lt;a href=&quot;#矩阵相乘&quot; class=&quot;headerlink&quot; title=&quot;矩
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>TensorFlow</title>
    <link href="http://stark365.com/TensorFlow/"/>
    <id>http://stark365.com/TensorFlow/</id>
    <published>2019-04-06T02:55:52.001Z</published>
    <updated>2019-04-08T08:28:52.439Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h1><h2 id="TensorFlow-特点"><a href="#TensorFlow-特点" class="headerlink" title="TensorFlow 特点"></a>TensorFlow 特点</h2><ol><li>良好的可移植性</li><li>多语言支持</li><li>高度的灵活性与效率</li><li>社区庞大</li></ol><h2 id="前端系统"><a href="#前端系统" class="headerlink" title="前端系统"></a>前端系统</h2><p>定义程序图的机构</p><h2 id="后端系统"><a href="#后端系统" class="headerlink" title="后端系统"></a>后端系统</h2><p>运算图结构</p><h2 id="Operation-OP"><a href="#Operation-OP" class="headerlink" title="Operation/OP"></a>Operation/OP</h2><p>只要使用 Tensorflow 的 API 定义的函数都是OP</p><h2 id="Tensor-张量"><a href="#Tensor-张量" class="headerlink" title="Tensor/张量"></a>Tensor/张量</h2><p>仅指代的是数据</p><h2 id="图-Graph"><a href="#图-Graph" class="headerlink" title="图 Graph"></a>图 Graph</h2><p>图默认已经注册，一组表示 tf.Operation 计算单位的对象和 tf.Tensor 表示操作之间流动的数据单元的对象</p><blockquote><p>tf.get_default_graph() 可以获取默认图</p><p>op、sess、tensor 都有 graph 属性</p></blockquote><h3 id="创建图"><a href="#创建图" class="headerlink" title="创建图"></a>创建图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">g = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    a = tf.constant(<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure><h2 id="会话-Session"><a href="#会话-Session" class="headerlink" title="会话 Session"></a>会话 Session</h2><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ol><li>运行图的结构</li><li>分配资源计算</li><li>掌握资源（变量的资源，队列，线程）</li></ol><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session(graph=g) <span class="keyword">as</span> sess:  <span class="comment"># graph 可以指定运行的图</span></span><br><span class="line">    sess.run(g)  <span class="comment"># run() 开启一个会话，分配资源，run() 结束后释放资源；g 为指定的图</span></span><br></pre></td></tr></table></figure><h3 id="run"><a href="#run" class="headerlink" title="run()"></a>run()</h3><p>run() 方法用于运行 ops 和计算 Tensor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run(fetches, feed_dict=<span class="literal">None</span>, graph=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><blockquote><p>fetches 嵌套列表，元组，namedtuple，dict或OrderedDict(重载的运算符也可以)</p><p>feed_dict 允许调用者覆盖图中指定张量的值，提供给 placeholder 使用(placeholder 是一个占位符,用于实时提供数据进行训练)</p></blockquote><p>返回值异常：</p><ul><li>RuntimeError:Session 处于无效状态，比如已关闭</li><li>TypeError:fetches 或 feed_dict 键是不合适的类型</li><li>ValueError:fetches 或 feed_dict 键无效或引用 Tensor 不存在</li></ul><h3 id="TensorFlow-Feed-操作"><a href="#TensorFlow-Feed-操作" class="headerlink" title="TensorFlow Feed 操作"></a>TensorFlow Feed 操作</h3><p>在程序执行的时候，不确定输入的是什么，提前预定位置</p><p>placeholder 提供占位符，run 时通过 feed_dict 指定参数</p><h2 id="Tensor-张量-1"><a href="#Tensor-张量-1" class="headerlink" title="Tensor 张量"></a>Tensor 张量</h2><h3 id="张量的阶和数据类型"><a href="#张量的阶和数据类型" class="headerlink" title="张量的阶和数据类型"></a>张量的阶和数据类型</h3><p>张量是 TensorFlow 基本的数据格式，一个类型化的 N 维度数组（tf.Tensor）,有三部分，名字、形状、数据类型。</p><table><thead><tr><th>阶</th><th>数学实例</th><th>Python</th><th>例子</th></tr></thead><tbody><tr><td>0</td><td>纯量</td><td>只有大小</td><td>s = 200</td></tr><tr><td>1</td><td>向量</td><td>大小和方向</td><td>v = [1, 2, 3]</td></tr><tr><td>2</td><td>矩阵</td><td>数据表</td><td>m = [[1, 2], [3, 4]]</td></tr></tbody></table><h3 id="张量属性"><a href="#张量属性" class="headerlink" title="张量属性"></a>张量属性</h3><p>graph 张亮所属的图</p><p>op 张量的操作名</p><p>name 张量的字符串描述</p><p>shape 张量的形状</p><h3 id="动态形状与静态形状"><a href="#动态形状与静态形状" class="headerlink" title="动态形状与静态形状"></a>动态形状与静态形状</h3><ul><li>静态形状：创建一个张量，初始化状态的形状<ul><li>tf.Tensor.get_shape 获取静态形状</li><li>tf.Tensor.get_shape() 更新 Tensor 对象的静态形状，通常用于再不能直接推断的情况下</li></ul></li><li>动态形状：一种描述原始张量在执行过程中的一种形状（动态变化）<ul><li>tf.reshape 创建一个具有不同动态形状的新张量</li></ul></li></ul><p>注意：</p><ul><li>转换静态形状的时候，不能跨阶数改变形状</li><li>对于已经固定或者设置静态形状的张量/变量，不能再次设置静态形状</li><li>tf.reshape() 动态创建新张量时，元素个数不能不匹配</li></ul><h3 id="生成张量"><a href="#生成张量" class="headerlink" title="生成张量"></a>生成张量</h3><p>创建所有元素为0的张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.zeros(shape, dtype=tf.float32, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>创建所有元素为1的张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.ones(shape, dtype=tf.float32, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>创建一个常数张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.ones(shape, dtype=tf.float32, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>创建随机张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.random_normal(shape, mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>, dtype=tf.float32, seed=<span class="literal">None</span>, name=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>mean: 平均值</p><p>stddev: 标准差</p><h3 id="张量类型转换"><a href="#张量类型转换" class="headerlink" title="张量类型转换"></a>张量类型转换</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.cast([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]], tf.float32)</span><br></pre></td></tr></table></figure><h3 id="张量的合并"><a href="#张量的合并" class="headerlink" title="张量的合并"></a>张量的合并</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.concat([a, b], axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><p>变量 op 能够持久化保存，而普通张量 op 无法持久化</p><h3 id="变量的创建"><a href="#变量的创建" class="headerlink" title="变量的创建"></a>变量的创建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.Variable(initial_value=<span class="literal">None</span>, name=<span class="literal">None</span>, trainable=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="变量必须要初始化"><a href="#变量必须要初始化" class="headerlink" title="变量必须要初始化"></a>变量必须要初始化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init_op = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><p>添加一个初始化所有变量的 op</p><p>需要在会话中开启 sess.run([init_op])</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;TensorFlow&quot;&gt;&lt;a href=&quot;#TensorFlow&quot; class=&quot;headerlink&quot; title=&quot;TensorFlow&quot;&gt;&lt;/a&gt;TensorFlow&lt;/h1&gt;&lt;h2 id=&quot;TensorFlow-特点&quot;&gt;&lt;a href=&quot;#TensorFl
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>深度学习介绍</title>
    <link href="http://stark365.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%8B%E7%BB%8D/"/>
    <id>http://stark365.com/深度学习介绍/</id>
    <published>2019-04-06T02:11:55.007Z</published>
    <updated>2019-04-06T02:56:13.985Z</updated>
    
    <content type="html"><![CDATA[<h1 id="深度学习介绍"><a href="#深度学习介绍" class="headerlink" title="深度学习介绍"></a>深度学习介绍</h1><p>深度学习中深度神经网络、卷积神经网络和递归神经网络已被应用计算机视觉、语音识别、自然语言处理、音频识别与生物信息学等领域并获得了极好的效果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;深度学习介绍&quot;&gt;&lt;a href=&quot;#深度学习介绍&quot; class=&quot;headerlink&quot; title=&quot;深度学习介绍&quot;&gt;&lt;/a&gt;深度学习介绍&lt;/h1&gt;&lt;p&gt;深度学习中深度神经网络、卷积神经网络和递归神经网络已被应用计算机视觉、语音识别、自然语言处理、音频识别与生物
      
    
    </summary>
    
      <category term="深度学习笔记" scheme="http://stark365.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>k-means 聚类</title>
    <link href="http://stark365.com/k-means/"/>
    <id>http://stark365.com/k-means/</id>
    <published>2019-04-06T00:29:47.074Z</published>
    <updated>2019-04-06T01:57:50.692Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="k-means-聚类"><a href="#k-means-聚类" class="headerlink" title="k-means 聚类"></a>k-means 聚类</h1><p>只有特征值没有目标值可以归为无监督学习。</p><h2 id="k-means-原理"><a href="#k-means-原理" class="headerlink" title="k-means 原理"></a>k-means 原理</h2><blockquote><p>k：把数据划分为多少个类别</p></blockquote><ol><li>随机在数据中抽取 k 个样本，当做 k 个类别的中心点。</li><li>计算其余的点分别到这 k 个点的距离，从中选出距离最近的一个点作为自己的标记，形成 k 个族群。</li><li>分别计算这 k 个族群的平均值，把 k 个平均值和之前的 k 个旧中心点进行比较，如果相同则结束聚类，否则把这 k 个平均值作为新的中心点，重复第二步。</li></ol><h2 id="sklearn-API"><a href="#sklearn-API" class="headerlink" title="sklearn API"></a>sklearn API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.cluster.KMeans</span><br></pre></td></tr></table></figure><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KMeans(n_clusters=<span class="number">8</span>,init=<span class="string">'k-means++'</span>)</span><br></pre></td></tr></table></figure><blockquote><p>n_clusters:开始的聚类中心数量</p><p>init:初始化方法，默认 k-means++</p></blockquote><blockquote><p>默认标记的类型，可以和真实值比较（不是值比较）</p></blockquote><h2 id="k-means-性能评估指标-轮廓系数"><a href="#k-means-性能评估指标-轮廓系数" class="headerlink" title="k-means 性能评估指标:轮廓系数"></a>k-means 性能评估指标:轮廓系数</h2><h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>$$ sc_i = \frac{b_i-a_i}{max(b_i,a_i)} $$</p><p>对于每个点 i 为聚类数据中的样本，bi 为 i 到其他族群的所有样本的距离最小值，ai 为 i 到本身族的距离平均值。</p><p>最终计算出所有的样本点的轮廓系数平均值。</p><p>最终轮廓系数会落在-1到1之间，越接近1越好，反之效果越差。</p><h3 id="sklearn-API-1"><a href="#sklearn-API-1" class="headerlink" title="sklearn API"></a>sklearn API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.silhouette_score</span><br></pre></td></tr></table></figure><h3 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">silhouette_score(X, labels)</span><br></pre></td></tr></table></figure><blockquote><p>X:特征值</p><p>labels:被聚类标记的目标值</p></blockquote><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>采用迭代式算法，直观且实用</p><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>容易收敛到局部最优解（多次聚类）</p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>聚类一般做在分类之前</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;k-means-聚类&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>逻辑回归</title>
    <link href="http://stark365.com/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <id>http://stark365.com/逻辑回归/</id>
    <published>2019-04-05T01:37:48.231Z</published>
    <updated>2019-04-05T09:38:55.367Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>逻辑回归主要解决二分类问题，可以获得概率。</p><p>逻辑回归需要<strong>标准化</strong>。</p><p>逻辑回归可以解决过拟合问题。</p><h2 id="sigmoid-函数"><a href="#sigmoid-函数" class="headerlink" title="sigmoid 函数"></a>sigmoid 函数</h2><p><img src="./sigmoid.gif" alt></p><p>sigmoid 函数可以把输入值转换为0到1之间的数然后输出,默认0.5。</p><h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>$$ g(z)=\frac{1}{1+e^-z} $$</p><blockquote><p>e固定值为2.71，z为回归结果</p></blockquote><p>输出为[0,1]区间的概率值，默认为0.5</p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>对数似然损失</p><p>对数似然损失存在多个局部最小值，目前无法解决。可以使用多次随机初始化,比较最小值结果；也可在求解过程中调整学习率</p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>梯度下降</p><h2 id="sklearn-API"><a href="#sklearn-API" class="headerlink" title="sklearn API"></a>sklearn API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.LogisticRegression</span><br></pre></td></tr></table></figure><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LogisticRegression(penalty=<span class="string">'l2'</span>,C=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure><ul><li>penalty 正则化方式</li><li>C 正则化力度</li></ul><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>广告点击率预测、是否患病预测、需家账号识别等。</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>适合需要的到一个分类概率的场景，简单速度快。</p><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>不好处理多分类问题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;逻辑回归&quot;&gt;&lt;a href=&quot;#逻辑回归
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>sklearn 模型保存预加载</title>
    <link href="http://stark365.com/skl%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E9%A2%84%E5%8A%A0%E8%BD%BD/"/>
    <id>http://stark365.com/skl模型保存预加载/</id>
    <published>2019-04-05T01:03:57.918Z</published>
    <updated>2019-04-05T01:38:16.130Z</updated>
    
    <content type="html"><![CDATA[<h1 id="sklearn-模型保存预加载"><a href="#sklearn-模型保存预加载" class="headerlink" title="sklearn 模型保存预加载"></a>sklearn 模型保存预加载</h1><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.externals <span class="keyword">import</span> joblib</span><br></pre></td></tr></table></figure><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><h3 id="保存"><a href="#保存" class="headerlink" title="保存"></a>保存</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">joblib.dump(rf, <span class="string">'test.pkl'</span>)</span><br></pre></td></tr></table></figure><blockquote><p>rf 为模型</p></blockquote><h3 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">estimator = joblib.load(<span class="string">'test.pkl'</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;sklearn-模型保存预加载&quot;&gt;&lt;a href=&quot;#sklearn-模型保存预加载&quot; class=&quot;headerlink&quot; title=&quot;sklearn 模型保存预加载&quot;&gt;&lt;/a&gt;sklearn 模型保存预加载&lt;/h1&gt;&lt;h2 id=&quot;API&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>岭回归</title>
    <link href="http://stark365.com/%E5%B2%AD%E5%9B%9E%E5%BD%92/"/>
    <id>http://stark365.com/岭回归/</id>
    <published>2019-04-03T06:20:17.238Z</published>
    <updated>2019-04-03T06:39:22.023Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="岭回归"><a href="#岭回归" class="headerlink" title="岭回归"></a>岭回归</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>带有正则化的线性回归</p><h2 id="sklearn-API"><a href="#sklearn-API" class="headerlink" title="sklearn API"></a>sklearn API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.Ridge</span><br></pre></td></tr></table></figure><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Ridge(alpha=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure><p>具有L2正则化的线性最小二乘法</p><ul><li>alpha( \(\lambda\) ):正则化力度</li><li>coef_:回归系数</li></ul><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>岭回归得到的回归系数更符合实际，更可靠。另外，能让估计参数的波动范围变小，变得稳定。在存在病态数据偏多的研究中有较大的实用价值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;岭回归&quot;&gt;&lt;a href=&quot;#岭回归&quot; 
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>正则化</title>
    <link href="http://stark365.com/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <id>http://stark365.com/正则化/</id>
    <published>2019-04-03T06:14:32.673Z</published>
    <updated>2019-04-03T06:16:06.840Z</updated>
    
    <content type="html"><![CDATA[<h1 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h1><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p>可以使得W的每个元素都很小，趋近于0</p><h2 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h2><p>越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;L2正则化&quot;&gt;&lt;a href=&quot;#L2正则化&quot; class=&quot;headerlink&quot; title=&quot;L2正则化&quot;&gt;&lt;/a&gt;L2正则化&lt;/h1&gt;&lt;h2 id=&quot;作用&quot;&gt;&lt;a href=&quot;#作用&quot; class=&quot;headerlink&quot; title=&quot;作用&quot;&gt;&lt;/a&gt;作
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>欠拟合与过拟合</title>
    <link href="http://stark365.com/%E6%AC%A0%E6%8B%9F%E5%90%88%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88/"/>
    <id>http://stark365.com/欠拟合与过拟合/</id>
    <published>2019-04-03T05:34:08.929Z</published>
    <updated>2019-04-15T00:50:32.169Z</updated>
    
    <content type="html"><![CDATA[<h1 id="欠拟合与过拟合"><a href="#欠拟合与过拟合" class="headerlink" title="欠拟合与过拟合"></a>欠拟合与过拟合</h1><h2 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h2><p>一个假设在训练数据上能够获得比其他假设更好的拟合，但是在训练数据外的数据集上却不能很好地拟合数据，此时认为这个假设出现了过拟合现象。（模型过于复杂）</p><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><p>原始特征过多，存在一些嘈杂特征，模型过于复杂是因为模型尝试去兼顾各个测试数据点。</p><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><ul><li>进行特征选择，消除关联性大的特征</li><li>交叉验证，让所有数据都有进行过训练</li><li>正则化</li></ul><h2 id="欠拟合"><a href="#欠拟合" class="headerlink" title="欠拟合"></a>欠拟合</h2><p>一个假设在训练数据上不能获得更好的拟合，但是在训练数据外的数据集上也不能很好的拟合数据，此时认为这个假设出现了过拟合的现象。（模型过于简单）</p><h3 id="原因-1"><a href="#原因-1" class="headerlink" title="原因"></a>原因</h3><p>学习数据的特征过少</p><h3 id="解决方法-1"><a href="#解决方法-1" class="headerlink" title="解决方法"></a>解决方法</h3><p>增加数据的特征数量</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;欠拟合与过拟合&quot;&gt;&lt;a href=&quot;#欠拟合与过拟合&quot; class=&quot;headerlink&quot; title=&quot;欠拟合与过拟合&quot;&gt;&lt;/a&gt;欠拟合与过拟合&lt;/h1&gt;&lt;h2 id=&quot;过拟合&quot;&gt;&lt;a href=&quot;#过拟合&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="http://stark365.com/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>http://stark365.com/线性回归/</id>
    <published>2019-04-02T05:15:23.285Z</published>
    <updated>2019-04-03T06:19:30.057Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p>寻找一种能预测的趋势,需要做标准化处理。</p><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>线性回归通过一个或者多个<strong>自变量</strong>(<em>特征值</em>)与<strong>因变量</strong>(<em>目标值</em>)之间进行建模的回归分析，其中可以认为一个或者多个自变量之间的线性组合。</p><p>一元线性回归：涉及到的变量只有一个</p><p>多元线性回归：涉及到多个变量</p><h2 id="线性关系模型"><a href="#线性关系模型" class="headerlink" title="线性关系模型"></a>线性关系模型</h2><p>一个通过属性的线性组合来进行预测的函数</p><p>公式；</p><p>$$ f(x)=w_1x_1+w_2x_2+···+w_\alpha x_\alpha + b $$</p><blockquote><p>\(w\) 为权重，\(b\)为偏置顶</p></blockquote><h2 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h2><p>(m行, l列)*(l行, n列) = (m行, n列)</p><h2 id="通用公式"><a href="#通用公式" class="headerlink" title="通用公式"></a>通用公式</h2><p>$$ h(w)=w_0+w_1x_1+w_2x_2+···=w^Tx $$</p><p>其中\(w,x\)为矩阵：</p><p>$$ w=\begin{pmatrix}w_0\ w_1\ w_2\end{pmatrix} $$</p><p>$$ x=\begin{pmatrix}1\ x_1\ x_2\end{pmatrix} $$</p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><ul><li>\(y_i为第i个训练样本的真实值\)</li><li>\(h_w(x_i)为i个训练样本特征值组合预测函数\)</li></ul><h3 id="总损失定义："><a href="#总损失定义：" class="headerlink" title="总损失定义："></a>总损失定义：</h3><p>$$ J(\theta)=(h_w(x_1)-y_1)^2+(h_w(x_2)-y_2)^2+···+(h_w(x_m)-y_m)^2 $$</p><p>$$=\sum_{i=1}^{m}(h_w(x_i)-y_i)^2$$</p><p>又称<strong>最小二乘法</strong></p><h2 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h2><p>当特征数量 n 较大时运算代价很大，因为矩阵逆运算时间复杂度为 \(O(n^3)\),通常来说当 n 小于 10W 时是可以接受的。正规方程只适用于线性模型。不能解决拟合问题。</p><h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><p>沿着函数下降的方向找，最后找到误差的最低点，然后更新 W 值。梯度下降适合10W以上数据集使用，反之适合正规方程。梯度下降适用于各种类型的模型。</p><h2 id="sklearn-API"><a href="#sklearn-API" class="headerlink" title="sklearn API"></a>sklearn API</h2><h3 id="正规方程-1"><a href="#正规方程-1" class="headerlink" title="正规方程"></a>正规方程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.LinearRegression</span><br></pre></td></tr></table></figure><p><strong>注意</strong>:需要将数据转换为二维数组</p><p><strong>警告</strong>:容易出现过拟合，需要进行L2正则化</p><h3 id="梯度下降-1"><a href="#梯度下降-1" class="headerlink" title="梯度下降"></a>梯度下降</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.SGDRegressor</span><br></pre></td></tr></table></figure><h2 id="回归性能评估"><a href="#回归性能评估" class="headerlink" title="回归性能评估"></a>回归性能评估</h2><h3 id="均方误差-Mean-Squared-Error-评价机制"><a href="#均方误差-Mean-Squared-Error-评价机制" class="headerlink" title="均方误差(Mean Squared Error)评价机制"></a>均方误差(Mean Squared Error)评价机制</h3><p>公式：</p><p>$$ MSE=\frac{1}{m} \sum_{i=1} ^{m} (y^i-y_z)^2 $$</p><blockquote><p>\(y^i\) 为预测值，\(y_z\) 为真实值</p></blockquote><h3 id="sklearn-API-1"><a href="#sklearn-API-1" class="headerlink" title="sklearn API"></a>sklearn API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.mean_squared_error</span><br></pre></td></tr></table></figure><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mean_squared_error(y_true,y_pred)</span><br></pre></td></tr></table></figure><blockquote><p>y_true 标准化之前的真实值</p><p>y_pred 预测值</p><p>返回浮点数结果</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;线性回归&quot;&gt;&lt;a href=&quot;#线性回归
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>随机森林</title>
    <link href="http://stark365.com/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"/>
    <id>http://stark365.com/随机森林/</id>
    <published>2019-04-01T08:39:02.231Z</published>
    <updated>2019-04-01T09:33:56.695Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>随机森林是一个包含多个决策树的分类器，并且输出的类别是由个别树输出的类别的众数而定。最终结果是由全部决策树投票产生。</p><h2 id="集成学习方法"><a href="#集成学习方法" class="headerlink" title="集成学习方法"></a>集成学习方法</h2><p>集成学习方法通过建立几个模型组合来解决单一预测问题，他的工作原理是<strong>生成多个分类器/模型</strong>，各自独立地学习和作出预测，这些预测最后结合成单预测，因此优于任何一个单分类的预测。</p><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><p>假设有 N 个样本，M 个特征。</p><p>单棵树建立的过程：</p><ol><li>随机在 N 个样本中抽取一个，重复 N 次，有放回</li><li>随机在 M 个特征中选择 m 个(m &lt; M)特征</li></ol><p>建立10棵决策树</p><h2 id="sklearn-API"><a href="#sklearn-API" class="headerlink" title="sklearn API"></a>sklearn API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.ensemble.RandomForestClassifier</span><br></pre></td></tr></table></figure><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RandomForestClassifier(n_estimators=<span class="number">10</span>, criterion=<span class="string">'gini'</span>, max_depth=<span class="literal">None</span>, bootstrap=<span class="literal">True</span>, random_state=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><ul><li>随机森林分类器</li><li>n_estimators: 正整数，森林的数目量，一般为120，200，300，500，800，1200</li><li>criteria：字符串，分割特征的测量方法</li><li>max_depth：正整数，树的最大深度，一般为5，8，15，25，30</li><li>max_features：每个决策树的最大特征数量<ul><li>‘aoto’ 默认选择特征数开根号</li><li>‘sqrt’ 开根号</li><li>‘log2’ 求以2为底的指数</li><li>None 取全部特征</li></ul></li><li>bootstrap：布尔类型，是否在构建树时使用放回抽样</li></ul><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul><li>具有极好的准确率</li><li>能够有效的运行在大数据集上</li><li>能够处理具有高纬度特征的输入样本，并且不需要降维</li><li>能够评估各个特征在分类问题上的重要性</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;随机森林&quot;&gt;&lt;a href=&quot;#随机森林
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>决策树</title>
    <link href="http://stark365.com/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    <id>http://stark365.com/决策树/</id>
    <published>2019-04-01T02:16:23.838Z</published>
    <updated>2019-04-01T08:38:26.872Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>决策树思想的来源非常朴素，程序设计中的条件分支结构就是 if-then 结构，最早的决策树就是利用这类结构分割数据的一种分类学习方法。</p><h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h2><h3 id="信息量计算"><a href="#信息量计算" class="headerlink" title="信息量计算"></a>信息量计算</h3><p>$$ H=-(P_1logP_1+P_2logP_2+···+P_nlogP_n) $$</p><p>\(H\) 的专业术语称之为<strong>信息熵</strong>，单位为<strong>比特</strong>。</p><h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>$$ H(X)=\sum_{x\epsilon X} P(x)logP(x) $$</p><blockquote><p>信息和消除不确定性是相联系的，信息熵越大，不确定性就越大。</p></blockquote><!-- ## 划分依据 --><h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><p>特征 A 对训练数据集 D 的信息增益 g(D,A) 定义为集合 D 的信息熵 H(D) 与特征 A 给定条件下 D 的信息条件熵 H(D|A) 之差。</p><h3 id="公式-1"><a href="#公式-1" class="headerlink" title="公式"></a>公式</h3><p>$$ g(D,A)=H(D)-H(D|A) $$</p><blockquote><p>信息增益表示得知特征 X 的信息而使得类 Y 的信息的不确定性减少的程度。</p></blockquote><h2 id="sklearn-决策树-API"><a href="#sklearn-决策树-API" class="headerlink" title="sklearn 决策树 API"></a>sklearn 决策树 API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.tree.DecisionTreeClassifier</span><br></pre></td></tr></table></figure><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DecisionTreeClassifier(criterion=<span class="string">'gini'</span>, max_depth=<span class="literal">None</span>, random_state=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><ul><li>criterion 默认是’gini’系数，也可以选择信息增益的熵’entropy’</li><li>max_depth 树的深度大小</li><li>random_state 随机数种子</li></ul><h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><ul><li>decision_path 返回决策树的路径</li></ul><h2 id="决策树的结构可视化"><a href="#决策树的结构可视化" class="headerlink" title="决策树的结构可视化"></a>决策树的结构可视化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sklearn.tree.export_graphviz()</span><br><span class="line">export_graphviz(estimator, out_file=<span class="string">'tree.dot'</span>, feature_names=[<span class="string">''</span>,<span class="string">''</span>])</span><br></pre></td></tr></table></figure><blockquote><p>estimator 估计器对象<br>out_file 保存路径<br>feature_names 特征处理后的特征名</p></blockquote><p>安装 graphviz 工具</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install graphviz</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dot -Tpng tree.dot -o tree.png</span><br></pre></td></tr></table></figure><h2 id="决策树优缺点"><a href="#决策树优缺点" class="headerlink" title="决策树优缺点"></a>决策树优缺点</h2><h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><ul><li>简单的理解和解释，树木可视化</li><li>需要很少的数据准备，其他算法通常需要数据归一化</li></ul><h3 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h3><ul><li>决策树学习者可以创建不能很好地推广数据的过于复杂的树，被称之为<strong>过拟合</strong></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; 
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>模型选择与调优</title>
    <link href="http://stark365.com/%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98/"/>
    <id>http://stark365.com/模型选择与调优/</id>
    <published>2019-03-31T08:14:17.700Z</published>
    <updated>2019-04-01T02:08:58.029Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="模型选择与调优"><a href="#模型选择与调优" class="headerlink" title="模型选择与调优"></a>模型选择与调优</h1><h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p>为了让被评估的模型更加精确可信。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>把训练集数据分成 n 等份，每一份包含训练集和验证集，求每一份模型准确率再计算平均值。</p><h2 id="超参数搜索-网格搜索"><a href="#超参数搜索-网格搜索" class="headerlink" title="超参数搜索/网格搜索"></a>超参数搜索/网格搜索</h2><p>通常情况下，很多算法参数需要手动指定，如 k-近邻算法 中的 k 值，这种参数叫<strong>超参数</strong>。但是手动调制过程繁杂，所以需要对模型进行预设几种超参数组合，每组超参数都采用交叉验证来进行评估。最后选出最优参数组合建立模型。</p><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.GridSearchCV</span><br></pre></td></tr></table></figure><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.GridSearchCV(estimator, param_grid=<span class="literal">None</span>, cv=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>estimator: 估计器对象</li><li>param_grid：估计器参数字典：{“n_neighbors”: [1, 3, 5]}</li><li>cv：交叉验证折数</li></ul><p>方法：</p><ul><li>fit: 输入训练数据</li><li>score: 准确率</li><li>best_score_: 在交叉验证中最高准确率</li><li>best_estimator_: 最好的参数模型</li><li>cv_results_: 每次交叉验证后的验证集准确率结果和训练集准确率结果</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;模型选择与调优&quot;&gt;&lt;a href=&quot;#模
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>分类模型评估</title>
    <link href="http://stark365.com/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5/"/>
    <id>http://stark365.com/混淆矩阵/</id>
    <published>2019-03-31T07:41:57.604Z</published>
    <updated>2019-03-31T08:04:51.342Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="分类模型评估"><a href="#分类模型评估" class="headerlink" title="分类模型评估"></a>分类模型评估</h1><h2 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h2><p>在分类任务下，预测结果(Predicted Condition)与正确标记(True Condition)之间存在四种不同的组合，构成混淆矩阵(适用于多分类)。</p><table><thead><tr><th></th><th style="text-align:right">预测正例</th><th style="text-align:center">预测假例</th></tr></thead><tbody><tr><td>真实正例</td><td style="text-align:right">真正例TP</td><td style="text-align:center">伪反例FN</td></tr><tr><td>真实假例</td><td style="text-align:right">伪正例FP</td><td style="text-align:center">真反例TN</td></tr></tbody></table><h2 id="召回率"><a href="#召回率" class="headerlink" title="召回率"></a>召回率</h2><p><strong>真实为正例</strong>的样本中预测结果为正例的比例。</p><table><thead><tr><th></th><th style="text-align:right">预测正例</th><th style="text-align:center">预测假例</th></tr></thead><tbody><tr><td>真实正例</td><td style="text-align:right"><strong><em>真正例TP</em></strong></td><td style="text-align:center"><strong><em>伪反例FN</em></strong></td></tr><tr><td>真实假例</td><td style="text-align:right">伪正例FP</td><td style="text-align:center">真反例TN</td></tr></tbody></table><h2 id="F1-score"><a href="#F1-score" class="headerlink" title="F1-score"></a>F1-score</h2><p>F1-score 反映了模型的稳健性。</p><p>$$ F1=\frac{2TP}{2TP+FN+FP}=\frac{2·Precision·Recall}{Precision+Recall} $$</p><h2 id="分类模型评估-API"><a href="#分类模型评估-API" class="headerlink" title="分类模型评估 API"></a>分类模型评估 API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.classification_report</span><br></pre></td></tr></table></figure><h2 id="分类模型评估用法"><a href="#分类模型评估用法" class="headerlink" title="分类模型评估用法"></a>分类模型评估用法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.metrics.classification_report(y_true, y_pred, target_names=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><ul><li>y_true: 真实目标值</li><li>y_pred: 估计器预测目标值</li><li>target_names: 目标类别名称</li><li><strong><em>return</em></strong>: 每个类别精确率与召回率</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;分类模型评估&quot;&gt;&lt;a href=&quot;#分类
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>朴素贝叶斯</title>
    <link href="http://stark365.com/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    <id>http://stark365.com/朴素贝叶斯/</id>
    <published>2019-03-31T01:53:10.007Z</published>
    <updated>2019-03-31T06:25:09.661Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="朴素贝叶斯算法"><a href="#朴素贝叶斯算法" class="headerlink" title="朴素贝叶斯算法"></a>朴素贝叶斯算法</h1><p>朴素贝叶斯算法基于条件概率，特征与特征之间相互独立互不影响。</p><h2 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h2><p>$$ P(C|W)=\frac{P(W|C)P(C)}{P(W)} $$</p><blockquote><p>\(W\)为给定文档的特征值（频数统计，预测文档提供），\(C\)为文档类别。</p></blockquote><p>公式可理解为：</p><p>$$ P(C|F_1,F_2,…)=\frac{P(F_1,F_2,…|C)P(C)}{P(F_1,F_2,…)} $$</p><blockquote><p>其中\(C\)可以是不同类别。</p></blockquote><h3 id="公式举例"><a href="#公式举例" class="headerlink" title="公式举例"></a>公式举例</h3><ul><li><p>\(P(C)\)为每个文档类别的概率（某文档类别数/总文档数）</p></li><li><p>\(P(W|C)\)为给定类别下特征（被预测文档中出现的词）的概率</p><ul><li>计算方法：\(P(F_1|C)=\frac{N_I}{N}\)</li><li>\(N_i\)为该\(F_1\)词在\(C\)类别所有文档中出现的次数</li><li>\(N\)为所属类别\(C\)下的文档所有词出现的次数和</li></ul></li><li><p>\(P(F_1,F_2,…)\)预测文档中每个词的概率</p></li></ul><p>在贝叶斯公式中会因为某个特征为0而导致最终概率结果为0，为避免这种不合理情况的发生，<strong>需要添加拉普拉斯平滑系数</strong>。</p><h2 id="拉普拉斯平滑"><a href="#拉普拉斯平滑" class="headerlink" title="拉普拉斯平滑"></a>拉普拉斯平滑</h2><p>公式：</p><p>$$ P(F_1|C)=\frac{N_I+\alpha}{N+\alpha m} $$</p><blockquote><p>\(\alpha\)为指定的系数，一般为1，m为训练文档中统计出的 <strong>特征词</strong> 个数。</p></blockquote><h2 id="sklearn-API"><a href="#sklearn-API" class="headerlink" title="sklearn API"></a>sklearn API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.vaive_bayes.MultinomialNB</span><br></pre></td></tr></table></figure><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MultinomialNB(alpha=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure><blockquote><p>alpha 为拉普拉斯平滑系数</p></blockquote><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>若训练集误差较大，则会严重影响结果。</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><ul><li>优点：<ul><li>具有稳定的分类效率</li><li>对缺失数据不太敏感</li><li>分类准确度高</li></ul></li><li>缺点：<ul><li>当样本属性具有关联性时效果会下降</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;朴素贝叶斯算法&quot;&gt;&lt;a href=&quot;#朴
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>概率基础</title>
    <link href="http://stark365.com/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/"/>
    <id>http://stark365.com/概率基础/</id>
    <published>2019-03-31T01:11:26.005Z</published>
    <updated>2019-03-31T05:48:35.488Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="概率基础"><a href="#概率基础" class="headerlink" title="概率基础"></a>概率基础</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>概率定义为一件事情发生的可能性。</p><h1 id="联合概率和条件概率"><a href="#联合概率和条件概率" class="headerlink" title="联合概率和条件概率"></a>联合概率和条件概率</h1><h2 id="联合概率"><a href="#联合概率" class="headerlink" title="联合概率"></a>联合概率</h2><blockquote><p>包含多个条件，且所有条件同时成立的概率</p></blockquote><p>记做：\(P(A,B)=P(A)P(B)\)</p><h2 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h2><blockquote><p>事件 A 在另外一个事件 B 已经发生条件下的发生概率</p></blockquote><p>记做：\(P(A|B)\)</p><p>特性：\(P(A_1,A_2|B)=p(A_1|B)P(A_2|B)\)</p><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p><strong>此条件概率的成立，是由于 \(A_1,A_2\)相互独立的结果</strong>，相互独立即双方条件不相互影响。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;概率基础&quot;&gt;&lt;a href=&quot;#概率基础
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>K-近邻算法/KNN 算法</title>
    <link href="http://stark365.com/K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/"/>
    <id>http://stark365.com/K-近邻算法/</id>
    <published>2019-03-29T01:02:57.792Z</published>
    <updated>2019-03-31T01:58:02.340Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="K-近邻算法-KNN-算法"><a href="#K-近邻算法-KNN-算法" class="headerlink" title="K-近邻算法/KNN 算法"></a>K-近邻算法/KNN 算法</h1><p>如果一个样本在特征空间中的 k 个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。</p><p>最近邻居法采用<strong>向量空间模型</strong>来分类，概念为相同类别的案例，彼此的相似度高，而可以借由计算与已知类别案例之相似度，来评估未知类别案例可能的分类。</p><h2 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h2><h3 id="公式：-sqrt-a-1-b-1-2-a-2-b-2-2-a-3-b-3-2"><a href="#公式：-sqrt-a-1-b-1-2-a-2-b-2-2-a-3-b-3-2" class="headerlink" title="公式：  $$\sqrt{(a_1 - b_1)^2 + (a_2 - b_2)^2 + (a_3 - b_3)^2}$$"></a>公式：  $$\sqrt{(a_1 - b_1)^2 + (a_2 - b_2)^2 + (a_3 - b_3)^2}$$</h3><h2 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h2><p><strong>K-近邻算法需要做标准化处理</strong></p><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.neighbors.KNeighborsClassifier</span><br></pre></td></tr></table></figure><h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KNeighborsClassifier(n_neighbors=<span class="number">5</span>, algorithm=<span class="string">'auto'</span>)</span><br></pre></td></tr></table></figure><blockquote><p><strong>n_neighbors: int</strong> 查询默认使用的邻居数。</p></blockquote><blockquote><p><strong>algorithm: {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}</strong> 可选用于计算最近邻居的算法，’ball_tree’ 将使用 BallTree，’kd_tree’ 将使用 KDTree。’auto’ 将尝试根据传递给 fit 方法的值来决定最合适的算法。</p></blockquote><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>计算量大，性能问题严峻。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;K-近邻算法-KNN-算法&quot;&gt;&lt;a hr
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>算法分类</title>
    <link href="http://stark365.com/%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB/"/>
    <id>http://stark365.com/算法分类/</id>
    <published>2019-03-28T08:04:21.122Z</published>
    <updated>2019-04-06T00:29:55.034Z</updated>
    
    <content type="html"><![CDATA[<h1 id="算法分类"><a href="#算法分类" class="headerlink" title="算法分类"></a>算法分类</h1><h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><p>有特征值和目标值。</p><p>算法：</p><ul><li>分类：目标值为离散型<ul><li><a href="../K-近邻算法">K-近邻算法</a></li><li><a href="../朴素贝叶斯">朴素贝叶斯算法</a></li><li><a href="../决策树">决策树</a></li><li><a href="../随机森林">随机森林</a></li><li><a href="../逻辑回归">逻辑回归</a></li><li><a href>神经网络</a></li></ul></li><li>回归：目标值为连续型，目标值过多<ul><li><a href="../线性回归">线性回归</a></li><li><a href="../岭回归">岭回归</a></li></ul></li></ul><h2 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h2><p>只有特征值。</p><p>算法：</p><ul><li><a href="../k-means">k-means 聚类</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;算法分类&quot;&gt;&lt;a href=&quot;#算法分类&quot; class=&quot;headerlink&quot; title=&quot;算法分类&quot;&gt;&lt;/a&gt;算法分类&lt;/h1&gt;&lt;h2 id=&quot;监督学习&quot;&gt;&lt;a href=&quot;#监督学习&quot; class=&quot;headerlink&quot; title=&quot;监督学习&quot;&gt;&lt;/a
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>数据类型</title>
    <link href="http://stark365.com/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
    <id>http://stark365.com/数据类型/</id>
    <published>2019-03-28T07:54:52.096Z</published>
    <updated>2019-03-30T09:44:44.223Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><ul><li>离散型数据</li><li>连续型数据</li></ul><h2 id="离散型数据"><a href="#离散型数据" class="headerlink" title="离散型数据"></a>离散型数据</h2><p>由记录不同类别个体的数目所得到的数据，计数数据，所有数据全部为整数，而且不能再细分，也不能再进一步的提升精确度。</p><h2 id="连续型数据"><a href="#连续型数据" class="headerlink" title="连续型数据"></a>连续型数据</h2><p>变量可在某个范围内取任意数，可连续，如长度、时间、质量等，这类数通常是非整数，含有小数部分。</p><hr><p><strong>离散型数据区间内不可再分，而连续型数据区间内可再分</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数据类型&quot;&gt;&lt;a href=&quot;#数据类型&quot; class=&quot;headerlink&quot; title=&quot;数据类型&quot;&gt;&lt;/a&gt;数据类型&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;离散型数据&lt;/li&gt;
&lt;li&gt;连续型数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;离散型数据&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>Scikit-Learn 数据集 API</title>
    <link href="http://stark365.com/sklearn%E6%95%B0%E6%8D%AE%E9%9B%86API/"/>
    <id>http://stark365.com/sklearn数据集API/</id>
    <published>2019-03-28T05:45:22.517Z</published>
    <updated>2019-03-30T09:46:26.195Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Scikit-Learn-数据集-API"><a href="#Scikit-Learn-数据集-API" class="headerlink" title="Scikit-Learn 数据集 API"></a>Scikit-Learn 数据集 API</h1><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.datasets</span><br></pre></td></tr></table></figure><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datasets.load_*()  <span class="comment"># 获取 sklearn 内置的小型数据集。</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datasets_fetch_*(data_home=<span class="literal">None</span>)  <span class="comment"># 获取大规模数据集，从互联网上下载，data_home 需要指定下载目录。</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Scikit-Learn-数据集-API&quot;&gt;&lt;a href=&quot;#Scikit-Learn-数据集-API&quot; class=&quot;headerlink&quot; title=&quot;Scikit-Learn 数据集 API&quot;&gt;&lt;/a&gt;Scikit-Learn 数据集 API&lt;/h1&gt;&lt;
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>主成分分析 PCA</title>
    <link href="http://stark365.com/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    <id>http://stark365.com/主成分分析/</id>
    <published>2019-03-28T01:49:02.490Z</published>
    <updated>2019-03-30T09:45:54.995Z</updated>
    
    <content type="html"><![CDATA[<h1 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析 PCA"></a>主成分分析 PCA</h1><p>PCA 是一种分析、简化数据集的技术,目的是数据降维压缩，尽可能降低原数据的维数复杂度，会<strong>损失少量信息</strong>。</p><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.decomposition</span><br></pre></td></tr></table></figure><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PCA(n_components=<span class="number">0.9</span>) <span class="comment"># 小数表示特征信息保留百分比，整数表示特征保留数</span></span><br><span class="line">PCA.fit_transform(X)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;主成分分析-PCA&quot;&gt;&lt;a href=&quot;#主成分分析-PCA&quot; class=&quot;headerlink&quot; title=&quot;主成分分析 PCA&quot;&gt;&lt;/a&gt;主成分分析 PCA&lt;/h1&gt;&lt;p&gt;PCA 是一种分析、简化数据集的技术,目的是数据降维压缩，尽可能降低原数据的维数复杂
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>特征选择</title>
    <link href="http://stark365.com/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    <id>http://stark365.com/特征选择/</id>
    <published>2019-03-28T01:18:15.752Z</published>
    <updated>2019-04-03T06:10:25.725Z</updated>
    
    <content type="html"><![CDATA[<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>部分特征的相关度高，容易消耗计算机性能；部分特征对预测结果有影响。</p><h2 id="主要方法"><a href="#主要方法" class="headerlink" title="主要方法"></a>主要方法</h2><ul><li>Filter(过滤式):低方差特征VarianceThreshold</li><li>Embedded(嵌入式):正则化、决策树、神经网络</li><li>Wrapper(包裹式)</li></ul><h2 id="Filter-过滤式"><a href="#Filter-过滤式" class="headerlink" title="Filter(过滤式)"></a>Filter(过滤式)</h2><p>从方差大小考虑特征数据情况</p><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.feature_selection.VarianceThreshold</span><br></pre></td></tr></table></figure><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">VarianceThreshold(threshold = <span class="number">0.0</span>)</span><br><span class="line">Variance.fit_transform(<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;特征选择&quot;&gt;&lt;a href=&quot;#特征选择&quot; class=&quot;headerlink&quot; title=&quot;特征选择&quot;&gt;&lt;/a&gt;特征选择&lt;/h1&gt;&lt;p&gt;部分特征的相关度高，容易消耗计算机性能；部分特征对预测结果有影响。&lt;/p&gt;
&lt;h2 id=&quot;主要方法&quot;&gt;&lt;a href=&quot;#
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>标准缩放</title>
    <link href="http://stark365.com/%E5%BD%92%E4%B8%80%E5%8C%96%E6%A0%87%E5%87%86%E5%8C%96/"/>
    <id>http://stark365.com/归一化标准化/</id>
    <published>2019-03-27T06:48:29.554Z</published>
    <updated>2019-03-30T09:44:31.004Z</updated>
    
    <content type="html"><![CDATA[<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h1 id="标准缩放"><a href="#标准缩放" class="headerlink" title="标准缩放"></a>标准缩放</h1><h2 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a><strong>归一化</strong></h2><p>当多个特征同等重要的时候，需要进行归一化。使得某一个特征对最终结果不会造成较大影响。比如某个特征比其他特征位数大得多，导致其他特征对结果几乎没有影响时，则需要使用归一化。</p><h3 id="公式：-X’-frac-x-min-max-min-X’’-X’-mx-mi-mi"><a href="#公式：-X’-frac-x-min-max-min-X’’-X’-mx-mi-mi" class="headerlink" title="公式： $$X’=\frac{x-min}{max-min}$$ $$X’’=X’*(mx-mi)+mi$$"></a>公式： $$X’=\frac{x-min}{max-min}$$ $$X’’=X’*(mx-mi)+mi$$</h3><blockquote><p>x 为特征值，min 为最小特征值， max 为最大特征值，X’’ 为归一化后结果值，mx 为结果区间最大值， mi 为结果区间最小值</p></blockquote><p>归一化公式中最大值与最小值容易受到异常点影响，所以这种方法<strong>鲁棒性</strong>较差，只适合传统精确小数据场景。</p><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.MinMaxScaler</span><br></pre></td></tr></table></figure><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MinMaxScalar(feature_range=(<span class="number">0</span>,<span class="number">1</span>))  <span class="comment"># 缩小范围</span></span><br><span class="line">MinMaxScalar.fit_transform(X)</span><br></pre></td></tr></table></figure><h2 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a><strong>标准化</strong></h2><p>通过对原始数据进行变换把数据变换到均值为0，方差为1范围内。</p><h3 id="公式：-var-frac-x1-mean-2-x2-mean-2-···-n-每个特征的样本数-sigma-sqrt-var-X’-frac-x-mean-sigma"><a href="#公式：-var-frac-x1-mean-2-x2-mean-2-···-n-每个特征的样本数-sigma-sqrt-var-X’-frac-x-mean-sigma" class="headerlink" title="公式：   $$var=\frac{(x1-mean)^2+(x2-mean)^2+···}{n(每个特征的样本数)}$$ $$\sigma=\sqrt{var}$$  $$X’=\frac{x-mean}{\sigma}$$"></a>公式：   $$var=\frac{(x1-mean)^2+(x2-mean)^2+···}{n(每个特征的样本数)}$$ $$\sigma=\sqrt{var}$$  $$X’=\frac{x-mean}{\sigma}$$</h3><blockquote><p>mean 为平均值，σ 为标准差，var 为方差</p></blockquote><p>标准化中标准差可以应对异常点的数值突出，影响较小。在已有<strong>样本足够多的情况下比较稳定</strong>，适合现代嘈杂大数据场景。</p><h3 id="API-1"><a href="#API-1" class="headerlink" title="API"></a>API</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sklearn.preprocessing.StandardScaler</span><br></pre></td></tr></table></figure><h3 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sta = StandardScaler()</span><br><span class="line">sta.fit_stansform(X)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;标准缩放&quot;&gt;&lt;a href=&quot;#标准缩放
      
    
    </summary>
    
      <category term="机器学习笔记" scheme="http://stark365.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>学习笔记</title>
    <link href="http://stark365.com/README/"/>
    <id>http://stark365.com/README/</id>
    <published>2018-10-22T16:11:18.000Z</published>
    <updated>2019-04-14T06:10:58.571Z</updated>
    
    <content type="html"><![CDATA[<h1 id="机器学习笔记"><a href="#机器学习笔记" class="headerlink" title="机器学习笔记"></a>机器学习笔记</h1><ul><li>数据特征预处理<ul><li><a href="/归一化标准化">标准缩放</a></li></ul></li><li>数据降维<ul><li><a href="./特征选择">特征选择</a></li><li><a href="./主成分分析">主成分分析</a></li></ul></li><li>算法简述<ul><li><a href="./数据类型">数据类型</a></li><li><a href="./算法分类">算法分类</a></li></ul></li><li><a href="./skl模型保存预加载">scikit-learn 模型保存预加载</a></li><li>监督学习<ul><li>分类算法<ul><li><a href="./sklearn数据集API">scikit-learn 数据集 API </a></li><li><a href="./K-近邻算法">K-近邻/KNN</a></li><li><a href="./朴素贝叶斯">朴素贝叶斯</a><ul><li><a href="./概率基础">概率基础</a></li><li><a href="./混淆矩阵">分类模型评估</a></li><li><a href="./模型选择与调优">模型选择与调优</a></li></ul></li><li><a href="./决策树">决策树</a></li><li><a href="./随机森林">随机森林</a></li><li><a href="./逻辑回归">逻辑回归 策略:对数似然损失 优化:梯度下降</a></li></ul></li><li>回归算法<ul><li><a href="./线性回归">线性回归 策略:均方误差 优化:梯度下降</a><ul><li><a href="./欠拟合与过拟合">欠拟合与过拟合</a></li><li><a href="./正则化">L2正则化</a></li></ul></li><li><a href="./岭回归">岭回归</a></li></ul></li></ul></li><li>非监督学习(只有特征值)<ul><li><a href="./k-means">k-means 聚类</a></li></ul></li></ul><h1 id="深度学习笔记"><a href="#深度学习笔记" class="headerlink" title="深度学习笔记"></a>深度学习笔记</h1><ul><li>深度学习<ul><li><a href="./深度学习介绍">深度学习介绍</a></li></ul></li><li>TensorFlow<ul><li><a href="./TensorFlow">TensorFlow 入门</a></li><li><a href="./可视化学习">可视化学习</a></li><li><a href="./模型的保存与加载">模型的保存与加载</a></li><li><a href="./mathapi">运算 API</a></li><li><a href="./gdo">梯度下降 API</a></li><li><a href="./线程队列与IO操作">线程队列与IO操作</a></li><li><a href="./文件读取">文件读取</a></li><li><a href="./图像读取">图像读取</a></li><li><a href="./TFRecords">TFRecords</a></li><li><a href="./神经网络">神经网络 策略:交叉熵损失 优化:反向传播算法</a></li><li><a href="./卷积神经网络">卷积神经网络</a></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;机器学习笔记&quot;&gt;&lt;a href=&quot;#机器学习笔记&quot; class=&quot;headerlink&quot; title=&quot;机器学习笔记&quot;&gt;&lt;/a&gt;机器学习笔记&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;数据特征预处理&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;/归一化标准化&quot;&gt;标准缩放&lt;/a&gt;&lt;/li&gt;

      
    
    </summary>
    
      <category term="笔记目录" scheme="http://stark365.com/categories/%E7%AC%94%E8%AE%B0%E7%9B%AE%E5%BD%95/"/>
    
    
  </entry>
  
</feed>
